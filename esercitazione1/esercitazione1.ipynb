{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('TLN': conda)",
   "metadata": {
    "interpreter": {
     "hash": "739282abffc8079465c7416af47f8b6d2681da148d602a4884c4032805e054cf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Parte 1: Concept Similarity\n",
    "\n",
    "Nella prima parte utilizziamo 2 risorse lessicali per un task di **concept similarity**. Le risorse sono\n",
    "* Wordnet, utilizzando le API fornite da NLTK\n",
    "* WordSim353, un corpus in cui abbiamo una lista di triple (word1, word2, similarity value).\n",
    "\n",
    "L'obiettivo di questa parte è implementare 3 misure di similarity basate sulla struttura tassonomica di Wordnet:\n",
    "\n",
    "* *Wu Palmer Similarity*\n",
    "$$ \\operatorname{sim}(s1,s2) = \\frac{2\\cdot\\operatorname{depth}(LCS(s1,s2))}{\\operatorname{depth}(s1) + \\operatorname{depth}(s2)} $$\n",
    "\n",
    "Dove $LCS(s1,s2)$ è il *Lowest Common Subsumer*, ovvero il sysnset **comune** più vicino ai synsets $s1,s2$ nella gerarchia iperonimi/iponimi. $\\operatorname{depth}(s)$ è la profondità (distanza minima) del synset $s$ dalla radice.\n",
    "\n",
    "* *Shortest Path Similarity*\n",
    "$$ \\operatorname{sim}(s1,s2) = 2\\cdot\\operatorname{depthMax} - \\operatorname{len}(s1,s2) $$\n",
    "\n",
    "* *Leakcock-Chodorow Similarity*\n",
    "$$ \\operatorname{sim}(s1,s2) = -\\log\\frac{\\operatorname{len}(s1,s2)}{2\\cdot\\operatorname{depthMax}} $$\n",
    "\n",
    "\n",
    "$\\operatorname{depthMax}$ è una costante che caratterizza la massima profondità della tassomia. Dunque è la distanza tra la radice della tassomia e la foglia alla massima profondità. Dato che Wordnet partiziona il lessico in base a 4 Part-of-Speech (POS)(Noun, Verb, Adjective, Adverb), il valore $\\operatorname{depthMax}$ dipende dal particolare POS considerato. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/prf-ubuntu/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/prf-\n[nltk_data]     ubuntu/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import src.concept_similarity as cs\n",
    "import src.data_manager as dm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import nltk\n",
    "\n",
    "# required lexical resources/ corpus\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "source": [
    "### EDA del corpus WordSim353\n",
    "\n",
    "Vediamo alcuni esempi di annotazioni presenti nel corpus. Selezioniamo le coppie di parole che corrispondo rispettivamente al\n",
    "minimo, primo quartile, mediana, secondo quartile e massimo dello score di similarità."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      word1    word2  gold_score\n",
       "33     king  cabbage       0.023\n",
       "86    coast     hill       0.438\n",
       "176  record   number       0.631\n",
       "45   tennis   racket       0.756\n",
       "2     tiger    tiger       1.000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word1</th>\n      <th>word2</th>\n      <th>gold_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33</th>\n      <td>king</td>\n      <td>cabbage</td>\n      <td>0.023</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>coast</td>\n      <td>hill</td>\n      <td>0.438</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>record</td>\n      <td>number</td>\n      <td>0.631</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>tennis</td>\n      <td>racket</td>\n      <td>0.756</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tiger</td>\n      <td>tiger</td>\n      <td>1.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "\n",
    "wordsim353 = dm.WordSimCorpus(Path('data/WordSim353.csv'))\n",
    "wordsim_df = pd.DataFrame(wordsim353, columns=['word1','word2','gold_score'])\n",
    "\n",
    "example_words = pd.DataFrame()\n",
    "for qpos in [0.0, 0.25, 0.5, 0.75, 1.0]: # sample word pair for each quartile\n",
    "    quantile = wordsim_df['gold_score'].quantile(q=qpos, interpolation='nearest')\n",
    "    example_words = example_words.append(wordsim_df[wordsim_df['gold_score']== quantile].sample())\n",
    "\n",
    "example_words"
   ]
  },
  {
   "source": [
    "Da notare che :\n",
    "\n",
    "$$\\operatorname{sim}: S\\times S \\to \\mathbb{R}$$\n",
    "\n",
    "Ovvero le metriche di similarità prendono in input due synset e restituiscono uno score numerico. Dunque bisogna implementare un meccanismo che prenda in input due **word forms** e restituisca uno score di similarità considerando che per il fenomeno della **polisemia** una word-form può avere differenti significati e dunque appartenere a differenti synsets. A tal proposito definiamo la word similarity come:\n",
    "\n",
    "$$ \\operatorname{sim}(w_1, w_2) = \\operatorname*{max}_{\\substack{c_1 \\in \\operatorname{Syn}(w_1)\\\\ c_2 \\in \\operatorname{Syn}(w_2) }} \\operatorname{sim}(c_1,c_2)$$\n",
    "\n",
    "Dove $\\operatorname{Syn}(w)$ è l'insieme dei synsets in cui occorre la word-form $w$.\n",
    "\n",
    "Vediamo su questi esempi selezionati il comportamento delle rispettive metriche di similarità."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      word1    word2  gold_score  wu_palmer  shortest_path  leakcock_chodorow\n",
       "33     king  cabbage       0.023   0.689655          0.775           1.410987\n",
       "86    coast     hill       0.438   0.750000          0.900           2.104134\n",
       "176  record   number       0.631   0.923077          0.975           3.020425\n",
       "45   tennis   racket       0.756   0.733333          0.800           1.516347\n",
       "2     tiger    tiger       1.000   1.000000          1.000           3.713572"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word1</th>\n      <th>word2</th>\n      <th>gold_score</th>\n      <th>wu_palmer</th>\n      <th>shortest_path</th>\n      <th>leakcock_chodorow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33</th>\n      <td>king</td>\n      <td>cabbage</td>\n      <td>0.023</td>\n      <td>0.689655</td>\n      <td>0.775</td>\n      <td>1.410987</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>coast</td>\n      <td>hill</td>\n      <td>0.438</td>\n      <td>0.750000</td>\n      <td>0.900</td>\n      <td>2.104134</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>record</td>\n      <td>number</td>\n      <td>0.631</td>\n      <td>0.923077</td>\n      <td>0.975</td>\n      <td>3.020425</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>tennis</td>\n      <td>racket</td>\n      <td>0.756</td>\n      <td>0.733333</td>\n      <td>0.800</td>\n      <td>1.516347</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tiger</td>\n      <td>tiger</td>\n      <td>1.000</td>\n      <td>1.000000</td>\n      <td>1.000</td>\n      <td>3.713572</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "metrics = [(cs.wu_palmer_similarity, 'wu_palmer'), \n",
    "           (cs.shortest_path_similarity, 'shortest_path'),\n",
    "           (cs.leakcock_chodorow_similarity, 'leakcock_chodorow')]\n",
    "    \n",
    "    \n",
    "for metric, metric_name in metrics:\n",
    "    example_words[metric_name] = example_words.apply(lambda x: cs.word_similarity(x['word1'], x['word2'], metric), axis=1)\n",
    "    \n",
    "example_words\n"
   ]
  },
  {
   "source": [
    "Possiamo osservare che, per gli esempi selezionati, non sussiste un forte agreement con il \"gold score\".\n",
    "Inoltre il valore delle metriche non è direttamente comparabaile in quanto le scale sono differenti.\n",
    "\n",
    "In generale, si può osservare che all'aumentare della similarità indicata dal gold score, aumenta anche\n",
    "il valore calcolato delle tre metriche."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Correlazione\n",
    "Vediamo di seguito l'agreement tra i gli score di similarità target (presenti nel corpus come annotazioni) e quelli calcolati dalle rispettive metriche.\n",
    "\n",
    "Come primo step calcoliamo le metriche di similarità per ogni coppia di temini presenti nel corpus:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, metric_name in metrics:\n",
    "    wordsim_df[metric_name] = wordsim_df.apply(lambda x: cs.word_similarity(x['word1'], x['word2'], metric), axis=1)"
   ]
  },
  {
   "source": [
    "Di seguito calcoliamo gli indici di correlazione di pearson e spearman. Utilizziamo i metodi delle API di Pandas, ricordando dalla documentazione:\n",
    "\n",
    "> \"Compute pairwise correlation of columns, excluding NA/null values.\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   gold_score\n",
       "wu_palmer            0.329174\n",
       "shortest_path        0.257977\n",
       "leakcock_chodorow    0.351304"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gold_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>wu_palmer</th>\n      <td>0.329174</td>\n    </tr>\n    <tr>\n      <th>shortest_path</th>\n      <td>0.257977</td>\n    </tr>\n    <tr>\n      <th>leakcock_chodorow</th>\n      <td>0.351304</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "excluded_cols = [name for metric, name in metrics]\n",
    "(wordsim_df.corr(method='pearson')\n",
    "           .drop(excluded_cols,axis=1)\n",
    "           .drop('gold_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   gold_score\n",
       "wu_palmer            0.327861\n",
       "shortest_path        0.314281\n",
       "leakcock_chodorow    0.314281"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gold_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>wu_palmer</th>\n      <td>0.327861</td>\n    </tr>\n    <tr>\n      <th>shortest_path</th>\n      <td>0.314281</td>\n    </tr>\n    <tr>\n      <th>leakcock_chodorow</th>\n      <td>0.314281</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "(wordsim_df.corr(method='spearman')\n",
    "           .drop(excluded_cols,axis=1)\n",
    "           .drop('gold_score'))"
   ]
  },
  {
   "source": [
    "Entrambi gli indici, non sembrano indicare una forte correlazione positiva. Possiamo verificarlo visivamente dai seguenti scatter plot:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize=(26,8))\n",
    "for ax, metric_name in zip(axes, [name for metric, name in metrics]):\n",
    "    #ax.scatter(x=wordsim_df['gold_score'], y=wordsim_df[metric_name])\n",
    "    wordsim_df.plot.scatter(x='gold_score', y=metric_name, ax=ax)\n",
    "    ax.set_ylim(bottom=0.0)\n",
    "    ax.set_title(\"Gold Score vs {} similarity\".format(metric_name.replace('_',' ')))"
   ]
  },
  {
   "source": [
    "# Parte 2: Word Sense Disambiguation\n",
    "\n",
    "In questa seconda parte vedremo come utilizzare l'algoritmo *Lesk* per un task di *Word Sense Disambiguation* (WSD). Utilizzeremo un breve corpus di frasi, ognuna contenente un singolo senso polisemico che dovrà essere disambiguato utilizando l'algoritomo Lesk e dunque sfruttando le risorse lessicali codificate in WordNet."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'3.0'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import src.word_sense_disambiguation as wsd\n",
    "import numpy as np\n",
    "\n",
    "wn.synsets('word')[0]._wordnet_corpus_reader.get_version() # quick hack to retrieve wordnet version used by NLTK"
   ]
  },
  {
   "source": [
    "Ma cosa significa nella pratica che un termine è polisemico? Vediamo un semplice esempio per una frase presa dal corpus."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Chosen sentence: Arms bend at the elbow.\n\nArms sense: weaponry.n.01\nDefinition: weapons considered collectively\nExample: \n\nArms sense: coat_of_arms.n.01\nDefinition: the official symbols of a family, state, etc.\nExample: \n\nArms sense: arm.n.01\nDefinition: a human limb; technically the part of the superior limb between the shoulder and the elbow but commonly used to refer to the whole superior limb\nExample: \n\nArms sense: arm.n.02\nDefinition: any projection that is thought to resemble a human arm\nExample: the arm of the record player\n\nArms sense: weapon.n.01\nDefinition: any instrument or instrumentality used in fighting or hunting\nExample: he was licensed to carry a weapon\n\nArms sense: arm.n.04\nDefinition: the part of an armchair or sofa that supports the elbow and forearm of a seated person\nExample: \n\nArms sense: branch.n.01\nDefinition: a division of some larger or more complex organization\nExample: a branch of Congress\n\nArms sense: sleeve.n.01\nDefinition: the part of a garment that is attached at the armhole and that provides a cloth covering for the arm\nExample: \n\nArms sense: arm.v.01\nDefinition: prepare oneself for a military confrontation\nExample: The U.S. is girding for a conflict in the Middle East\n\nArms sense: arm.v.02\nDefinition: supply with arms\nExample: The U.S. armed the freedom fighters in Afghanistan\n\n"
     ]
    }
   ],
   "source": [
    "corpus_path = Path('data/sentences.txt')\n",
    "corpus = dm.WSDSentences(corpus_path)\n",
    "\n",
    "_, poly_word, sentence = corpus.get_sentences()[0]\n",
    "print(\"Chosen sentence: {}\\n\".format(sentence))\n",
    "\n",
    "for syn in wn.synsets(poly_word):\n",
    "    example = syn.examples()[0] if len(syn.examples()) != 0 else '' \n",
    "    print(\"{} sense: {}\\nDefinition: {}\\nExample: {}\\n\".format(poly_word, syn.name(), syn.definition(), example))"
   ]
  },
  {
   "source": [
    "Quindi per il termine \"Arm\" esistono differenti significati dipendenti dal contesto preso in considerazione. Nel caso specifico, il contesto espresso dalla frase\n",
    "si riferisce chiaramente ad \"Arm\" nel senso di parte anatomica.\n",
    "\n",
    "Di seguito utilizziamo l'algoritmo Lesk per disambiguare la parola indicata nel corpus."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[coat_of_arms, arms, blazon, blazonry] bend at the elbow. | coat_of_arms.n.01 | the official symbols of a family, state, etc.\n\nGermany sells [coat_of_arms, arms, blazon, blazonry] to Saudi Arabia. | coat_of_arms.n.01 | the official symbols of a family, state, etc.\n\nThe [key] broke in the lock. | key.n.01 | metal device shaped in such a way that when it is inserted into the appropriate lock the lock's mechanism can be rotated\n\nThe [Key, Francis_Scott_Key] problem was not one of quality but of quantity. | key.n.07 | United States lawyer and poet who wrote a poem after witnessing the British attack on Baltimore during the War of 1812; the poem was later set to music and entitled `The Star-Spangled Banner' (1779-1843)\n\nWork out the [solution] in your head. | solution.n.01 | a homogeneous mixture of two or more substances; frequently (but not necessarily) a liquid solution\n\nHeat the [solution, answer, result, resolution, solvent] to 75° Celsius. | solution.n.02 | a statement that solves a problem or explains how to solve the problem\n\nThe house was burnt to [ash] while the owner returned. | ash.n.01 | the residue that remains when something is burned\n\nThis table is made of [ash] wood. | ash.n.03 | strong elastic wood of any of various ash trees; used for furniture and tool handles and sporting goods such as baseball bats\n\nThe [NONE] with her boss took longer than she expected. |  | \n\nShe packed her [NONE] in her purse. |  | \n\nThe [categorization, categorisation, classification, compartmentalization, compartmentalisation, assortment] of the genetic data took two years. | categorization.n.03 | the act of distributing things into classes or categories of the same type\n\nThe journal Science published the [categorization, categorisation, classification, compartmentalization, compartmentalisation, assortment] this month. | categorization.n.03 | the act of distributing things into classes or categories of the same type\n\nHis cottage is near a small [forest, wood, woods]. | forest.n.01 | the trees and other plants in a large densely wooded area\n\nThe statue was made out of a block of [wood]. | wood.n.08 | a golf club with a long shaft used to hit long shots; originally made with a wooden head\n\n"
     ]
    }
   ],
   "source": [
    "    output_path = Path(\"output\")\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    out_file = output_path / 'wsd_sentences.txt'\n",
    "\n",
    "    with out_file.open('w') as file:\n",
    "        for key, word, sentence in corpus.get_sentences():\n",
    "            best_sense, _ = wsd.lesk_wsd(sentence, word)\n",
    "\n",
    "            if best_sense: # a sense is found for a given word\n",
    "                repl_string = '[{}]'.format(', '.join(best_sense.lemma_names()))\n",
    "                syn_name = best_sense.name()\n",
    "                syn_definition = best_sense.definition()\n",
    "            else:\n",
    "                repl_string = '[NONE]'\n",
    "                syn_name = ''\n",
    "                syn_definition = ''\n",
    "\n",
    "            repl_sentence = corpus.replace_polysemous_word(key, repl_string)\n",
    "            to_write = \"{} | {} | {}\\n\".format(repl_sentence, syn_name, syn_definition)\n",
    "            print(to_write)\n",
    "            file.write(to_write)\n"
   ]
  },
  {
   "source": [
    "La precedente cella costruisce le bag-of-words non considerando la rimozione delle stopword. Vediamo di seguito se e come influsice la rimozione delle stop words sull'algoritmo lesk."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    with out_file.open('w') as file:\n",
    "        for key, word, sentence in corpus.get_sentences():\n",
    "            best_sense, _ = wsd.lesk_wsd(sentence, word, stopwords=wsd.STOP_WORDS)\n",
    "\n",
    "            if best_sense: # a sense is found for a given word\n",
    "                repl_string = '[{}]'.format(', '.join(best_sense.lemma_names()))\n",
    "                syn_name = best_sense.name()\n",
    "                syn_definition = best_sense.definition()\n",
    "            else:\n",
    "                repl_string = '[NONE]'\n",
    "                syn_name = ''\n",
    "                syn_definition = ''\n",
    "\n",
    "            repl_sentence = corpus.replace_polysemous_word(key, repl_string)\n",
    "            to_write = \"{} | {} | {}\\n\".format(repl_sentence, syn_name, syn_definition)\n",
    "            print(to_write)\n",
    "            file.write(to_write)"
   ]
  },
  {
   "source": [
    " Analizziamo i risultati:\n",
    "* **Solamente** $5$ su $14$ de termini polisemici totali sono stati disambiguati correttamente, con un'accuratezza dunque dello $0.35$%.\n",
    "* In $2$ casi su $14$ l'algoritmo lesk non è riuscito a trovare un senso per il termine polisemico. Nello specifico, questo significa che non è r\n",
    "riuscito a trovare un senso in cui la signature e il contesto avessero un valore di overlap $>0$.\n",
    "* Un esempio peculiare è il caso delle 2 frasi:\n",
    "\n",
    ">Work out the [solution] in your head. | solution.n.01 | a homogeneous mixture of two or more substances; frequently (but not necessarily) a liquid solution\n",
    ">Heat the [solution, answer, result, resolution, solvent] to 75° Celsius. | solution.n.02 | a statement that solves a problem or explains how to solve the problem\n",
    "\n",
    "in cui l'algoritmo ha invertito esattamente i corrispettivi sensi corretti.\n",
    "\n",
    "* Inoltre, dalla seconda esecuzione, si può notare un peggioramento delle prestazione eliminando le stopwords.\n",
    "\n",
    "Come è possibile interpretare questi risultati? La riduzione delle prestazioni della seconda esecuzione ci fornisce un indizio importante. L'algoritmo con brevi frasi ha pessime prestazioni in quanto non riesce a trovare dei sensi con overlap $>0$, denotando dunque una certa dipendenza dalle stopwords, comportamento certamente non desiderabile, in quanto esse non catturano il contesto della frase."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### SemCor Evaluation\n",
    "\n",
    "Effettuiamo un task di word sense disambiguation utilizzando l'algoritmo Lesk su un differente corpus: *SemCor*. \n",
    "\n",
    "TODO struttura di SemCor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def accuracy(true, predicted):\n",
    "    correct_predictions = sum([true_sense.lower() == predicted_sense.lower() for true_sense, predicted_sense in zip(true, predicted)\n",
    "    if true_sense and predicted_sense])\n",
    "    return correct_predictions / len(true)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "semcor_files = [Path('data/semcor3.0/brown1/tagfiles/br-e21'),\n",
    "                Path('data/semcor3.0/brown1/tagfiles/br-j59'),\n",
    "                Path('data/semcor3.0/brown1/tagfiles/br-r07'),\n",
    "                Path('data/semcor3.0/brown1/tagfiles/br-k25'),\n",
    "                Path('data/semcor3.0/brown1/tagfiles/br-p01')]\n",
    "\n",
    "\n",
    "accuracy_scores = []\n",
    "for file_path in semcor_files:\n",
    "    semcor = dm.SemCorCorpus(file_path)\n",
    "\n",
    "    true_senses =  []\n",
    "    predicted_senses = []\n",
    "\n",
    "    for sentence, annotated_words in semcor.get_annotated_sentences():\n",
    "        for (word, true_sense_id) in annotated_words:\n",
    "            lesk_sense, _ = wsd.lesk_wsd(sentence, word)\n",
    "            lesk_sense_name = lesk_sense.name() if lesk_sense else None\n",
    "            \n",
    "            true_senses.append(true_sense_id)\n",
    "            predicted_senses.append(lesk_sense_name)\n",
    "    \n",
    "    accuracy_scores.append(accuracy(true_senses, predicted_senses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy on br-e21 file: 0.2364\nAccuracy on br-j59 file: 0.1656\nAccuracy on br-r07 file: 0.1641\nAccuracy on br-k25 file: 0.2310\nAccuracy on br-p01 file: 0.2581\nAchieved 0.211+-0.04 mean accuracy on 5 runs\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = np.array(accuracy_scores)\n",
    "for file, acc_score in  zip(semcor_files, accuracy_scores):\n",
    "    print(\"Accuracy on {} file: {:.4f}\".format(file.stem, acc_score))\n",
    "    \n",
    "print('Achieved {:.3f}+-{:.2f} mean accuracy on {} runs'.format(accuracy_scores.mean(),\n",
    "accuracy_scores.std(), len(accuracy_scores)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.23636363636363636,\n",
       " 0.165625,\n",
       " 0.16412213740458015,\n",
       " 0.2310126582278481,\n",
       " 0.25806451612903225]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "accuracy_scores"
   ]
  }
 ]
}