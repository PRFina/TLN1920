{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd000c4925ce5d24b744b1d4673b76423a641f8c01c448e9592271d32b0e3be0330",
   "display_name": "Python 3.9.4 64-bit ('TLN': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Esercitazione 3: Teoria di Hanks\n",
    "\n",
    "In questa esercitazione vedremo come implementare un sistema basato sulla teoria di Patrick Hanks. Nello specifico vedremo come generare i **semantic types** per le **collocations dei fillers** a partire da frasi estratte da un corpus.\n",
    "\n",
    "\n",
    "\n",
    "L'approccio utilizzato si articola in 3 step principali:\n",
    "\n",
    "* **Sub-corpus Extraction**: dato in input un **verbo target** ed un corpus, vengono estratte tutte le frasi del corpus in cui esso occorre. La ricerca viene implementata dalla funzione `hanks.corpus_extraction`.\n",
    "\n",
    "* **Estrazione Fillers**: estrazione delle **collocations dei fillers** del verbo target.\n",
    "\n",
    "* **Semantic Types**: i fillers estratti vengono **clusterizzati** in semantic-types.\n",
    "\n",
    "Come risultato vengono visualizzate le collocations dei fillers e le informazioni di frequenza dei semantic types.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package brown to /home/prf/nltk_data...\n[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import src.hanks as hanks\n",
    "nltk.download('brown')\n",
    "import spacy \n",
    "\n",
    "import random\n",
    "random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VERB = 'eat'\n",
    "VALENCE = 2"
   ]
  },
  {
   "source": [
    "### Step 1: Sub-corpus Extraction\n",
    "\n",
    "Dato in input un *target verb* ed un corpus, vengono estratte dal corpus tutte le frasi in cui esso occorre. La ricerca viene implementata dalla funzione `hanks.corpus_extraction`\n",
    "\n",
    "Il corpus utilizzato in questa esercitazione è il *Brown Corpus* accessibile direttamente dalle API di NLTK."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Most',\n",
       " 'members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'U.S.',\n",
       " 'Senate',\n",
       " ',',\n",
       " 'because',\n",
       " 'they',\n",
       " 'are',\n",
       " 'human',\n",
       " ',',\n",
       " 'like',\n",
       " 'to',\n",
       " 'eat',\n",
       " 'as',\n",
       " 'high',\n",
       " 'on',\n",
       " 'the',\n",
       " 'hog',\n",
       " 'as',\n",
       " 'they',\n",
       " 'can',\n",
       " '.']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "selected_sents = hanks.corpus_extraction(INPUT_VERB, brown)\n",
    "selected_sents[0]"
   ]
  },
  {
   "source": [
    "Le frasi del brown corpus sono in realtà tokenizzate e rappresentate come una sequenza di token. A questo proposito è possibile utilizzare il `TreebankWordDetokenizer` per effettuare l'operazione inversa."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1. Why not put a cafe in each so the tourists would not have to travel too far to eat??\n2. We haven't had anything to eat all day\".\n3. I picked him up, and the length of him arched very carefully and gracefully and only a little wildly, and I could feel the coolness of that radiant, fire-colored body, like splendid ice, and I knew that he had eaten only recently because there were two whole and solid little lumps in the forepart of him, like fieldmice swallowed whole might make.\n4. they did not fall into pseudo-glamorous jobs on pseudo-glamorous magazines, but they did whatever nasty thing they could get in order to eat;;\n5. If this woman had delayed until after 11:20 to start her shopping, she would have had little time in which to prepare the substantial meal that was eaten at dinner in those days.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "detokenizer = TreebankWordDetokenizer()\n",
    "sents_sample = random.sample(selected_sents, 5)\n",
    "\n",
    "for i, sent in enumerate(sents_sample, start=1):\n",
    "    print(f\"{i}. {detokenizer.detokenize(sent)}\")\n"
   ]
  },
  {
   "source": [
    "Come si può osservare dall'output prodotto, in tutte le frasi compare il verbo \"eat\", si osservi come nella seconda e quinta frase, il verbo è nella forma past participle (\"eaten\")."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 2: Estrazione Fillers\n",
    "\n",
    "dati in input un insieme di frasi, il verbo target e la **valenza** dei suoi argomenti, estrae tutti le **collocations** dei **fillers** presenti nelle frasi con cui gli argomenti si realizzano. Lo step viene implementato dalla funzione `hanks.find_verb_fillers`. \n",
    "\n",
    "Per realizzare questo step si necessita di effettuare il **parsing sintattico** della frase in input. Il parsing viene effettuato utilizzando la libreria Spacy. Costruendo il grafo delle dipendenze sintattiche è possibile recuperare una o più occorrenze del verbo/i target (funzione `hanks.find_target_verbs`) e successivamente, analizzando le relazioni sintattiche, estrarre i fillers utilizzando la funzione `hanks.get_hanks_verb`. \n",
    "\n",
    "La funzione `hanks.get_hanks_verb` ritorna una *named tuple* **HanksVerb** che rappresenta la realizzazione sintattica degli argomenti del verbo, così come suggerito dalla teoria stessa."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "At the beginning of the school year, the new students don't eat the cereal right away, but within a short time they are eating it voraciously.\n-->\nHanksVerb(verb='eat', nargs=2, slot1='nsubj', slot2='dobj', filler1='students', filler2='cereal')\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "fillers = hanks.find_verb_fillers(selected_sents, INPUT_VERB, nlp_pipeline=nlp, valence=2)\n",
    "\n",
    "sent = fillers[4][0]\n",
    "hanks_verb = fillers[4][1]\n",
    "\n",
    "print(f\"{detokenizer.detokenize(sent)}\\n-->\\n{hanks_verb}\")"
   ]
  },
  {
   "source": [
    "### Step 3: Semantic Type Clustering e WSD\n",
    "\n",
    "In questo step, le informazioni estratte nel passo precedente e dunque le collocations dei fillers individuate, vengono clusterizzate in \"cluster semantici\" chiamati *semantic types*. \n",
    "\n",
    "La clusterizzazione utilizza  *WordNet* come sense-repository e dunque si necessita di un ulteriore step di **WSD**, effettuato dalla funzione `hanks.find_filler_senses` per disambiguare ed individuare il senso corretto associato al filler. Nell'esercitazione è stato utilizzato l'algoritmo **Lesk** con contesto di disambiguazione la frase stessa dove il filler del verbo occorre.\n",
    "\n",
    "Dopo lo step di WSD, la clusterizzazione (funzione `hanks.semantic_clustering`) avviene considerando il **lexicographer file** (funzione `synset.lexname()`) a cui il senso associato al filler appartiene. Il lexicographer file rappresenta il **super-senso** del filler.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None - Synset('citizenry.n.01')\nSynset('american_english.n.01') - Synset('fatty.a.01')\nSynset('one.s.03') - Synset('skin.v.02')\nNone - None\nSynset('scholar.n.01') - Synset('grain.n.02')\nNone - Synset('information_technology.n.01')\nSynset('scholar.n.01') - Synset('grain.n.02')\nNone - Synset('information_technology.n.01')\nSynset('one.n.01') - Synset('rider.n.01')\nSynset('iodine.n.01') - Synset('testis.n.01')\nNone - Synset('seeded_player.n.01')\nNone - Synset('net_income.n.01')\nSynset('world_health_organization.n.01') - Synset('celery.n.01')\nSynset('one.s.01') - Synset('soup.n.02')\nNone - Synset('food.n.02')\nSynset('helium.n.01') - Synset('nothing.r.01')\nSynset('one.s.01') - Synset('more.r.02')\nNone - Synset('supper.n.01')\nNone - Synset('dinner.n.01')\nNone - Synset('information_technology.n.01')\nSynset('fish.n.02') - Synset('torso.n.01')\nNone - Synset('one.s.01')\nNone - Synset('dust.v.02')\nSynset('helium.n.01') - None\nSynset('helium.n.01') - None\nSynset('helium.n.01') - Synset('breakfast.v.02')\nNone - Synset('other.s.04')\nNone - Synset('breakfast.v.02')\nNone - Synset('bread.v.01')\nNone - Synset('chicken.n.02')\nNone - Synset('wimp.n.01')\n"
     ]
    }
   ],
   "source": [
    "import nltk.wsd as wsd\n",
    "\n",
    "filler_senses = hanks.find_filler_senses(fillers, wsd.lesk)\n",
    "for sense1, sense2 in filler_senses:\n",
    "    print(f\"{sense1} - {sense2}\")"
   ]
  },
  {
   "source": [
    "Come si può osservare, la funzione `hanks.find_filler_senses` permette di passare dalla \"word-form\" del filler al \"word-meaning\", associando dunque un senso univoco.\n",
    "\n",
    "Il risultato di questa fase dipende essenzialmente da due fattori:\n",
    "* **Coverage** della risorsa lessicale utilizzata: \"il senso espresso dal filler è presente in WordNet?\" \n",
    "* **Performance** della funzione di WSD: a volte l'algoritmo lesk non riesce a trovare il senso wn da associare al filler (restituendo None)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(verb_name, fillers, filler_senses, semantic_types):\n",
    "    print(f\"Applying Hanks Theory for verb: {verb_name}\")\n",
    "    print()\n",
    "    print(\"Collocations Extracted:\\n\")\n",
    "    for  (_, hanks_verb), (filler1_sense, filler2_sense) in zip(fillers, filler_senses):\n",
    "        print(f\"filler: {hanks_verb.filler1} - {hanks_verb.filler2}\")\n",
    "        print(f\"senses: {filler1_sense} - {filler2_sense}\")\n",
    "        print('-------------------------------------------------------------')\n",
    "    print(\"\")\n",
    "    print(f\"Semantic Types Clusters for {verb_name}:\\n\")\n",
    "    tot = sum([freq for semantic_type, freq in semantic_types.most_common()])\n",
    "    for semantic_type, freq in semantic_types.most_common():\n",
    "        relative_freq = freq / tot * 100\n",
    "        print(f\"semantic type: {semantic_type}, occurence:{freq} ({relative_freq:0.2f}%)\")\n",
    "    print(\"******************************************************************\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Applying Hanks Theory for verb: eat\n\nCollocations Extracted:\n\nfiller: what - people\nsenses: None - Synset('citizenry.n.01')\n-------------------------------------------------------------\nfiller: Americans - fat\nsenses: Synset('american_english.n.01') - Synset('fatty.a.01')\n-------------------------------------------------------------\nfiller: one - skin\nsenses: Synset('one.s.03') - Synset('skin.v.02')\n-------------------------------------------------------------\nfiller: what - they\nsenses: None - None\n-------------------------------------------------------------\nfiller: students - cereal\nsenses: Synset('scholar.n.01') - Synset('grain.n.02')\n-------------------------------------------------------------\nfiller: they - it\nsenses: None - Synset('information_technology.n.01')\n-------------------------------------------------------------\nfiller: students - cereal\nsenses: Synset('scholar.n.01') - Synset('grain.n.02')\n-------------------------------------------------------------\nfiller: they - it\nsenses: None - Synset('information_technology.n.01')\n-------------------------------------------------------------\nfiller: I - rider\nsenses: Synset('one.n.01') - Synset('rider.n.01')\n-------------------------------------------------------------\nfiller: I - eggs\nsenses: Synset('iodine.n.01') - Synset('testis.n.01')\n-------------------------------------------------------------\nfiller: we - seed\nsenses: None - Synset('seeded_player.n.01')\n-------------------------------------------------------------\nfiller: which - profits\nsenses: None - Synset('net_income.n.01')\n-------------------------------------------------------------\nfiller: who - celery\nsenses: Synset('world_health_organization.n.01') - Synset('celery.n.01')\n-------------------------------------------------------------\nfiller: I - soup\nsenses: Synset('one.s.01') - Synset('soup.n.02')\n-------------------------------------------------------------\nfiller: They - food\nsenses: None - Synset('food.n.02')\n-------------------------------------------------------------\nfiller: He - nothing\nsenses: Synset('helium.n.01') - Synset('nothing.r.01')\n-------------------------------------------------------------\nfiller: I - more\nsenses: Synset('one.s.01') - Synset('more.r.02')\n-------------------------------------------------------------\nfiller: Charlie - supper\nsenses: None - Synset('supper.n.01')\n-------------------------------------------------------------\nfiller: she - dinner\nsenses: None - Synset('dinner.n.01')\n-------------------------------------------------------------\nfiller: you - it\nsenses: None - Synset('information_technology.n.01')\n-------------------------------------------------------------\nfiller: fish - bodies\nsenses: Synset('fish.n.02') - Synset('torso.n.01')\n-------------------------------------------------------------\nfiller: what - I\nsenses: None - Synset('one.s.01')\n-------------------------------------------------------------\nfiller: you - dust\nsenses: None - Synset('dust.v.02')\n-------------------------------------------------------------\nfiller: He - litle\nsenses: Synset('helium.n.01') - None\n-------------------------------------------------------------\nfiller: He - litle\nsenses: Synset('helium.n.01') - None\n-------------------------------------------------------------\nfiller: He - breakfast\nsenses: Synset('helium.n.01') - Synset('breakfast.v.02')\n-------------------------------------------------------------\nfiller: they - other\nsenses: None - Synset('other.s.04')\n-------------------------------------------------------------\nfiller: They - breakfast\nsenses: None - Synset('breakfast.v.02')\n-------------------------------------------------------------\nfiller: She - bread\nsenses: None - Synset('bread.v.01')\n-------------------------------------------------------------\nfiller: They - chickens\nsenses: None - Synset('chicken.n.02')\n-------------------------------------------------------------\nfiller: they - chickens\nsenses: None - Synset('wimp.n.01')\n-------------------------------------------------------------\n\nSemantic Types Clusters for eat:\n\nsemantic type: (None, None), occurence:19 (61.29%)\nsemantic type: ('noun.person', 'noun.food'), occurence:2 (6.45%)\nsemantic type: ('noun.communication', 'adj.all'), occurence:1 (3.23%)\nsemantic type: ('adj.all', 'verb.contact'), occurence:1 (3.23%)\nsemantic type: ('noun.quantity', 'noun.person'), occurence:1 (3.23%)\nsemantic type: ('noun.substance', 'noun.body'), occurence:1 (3.23%)\nsemantic type: ('noun.group', 'noun.plant'), occurence:1 (3.23%)\nsemantic type: ('adj.all', 'noun.substance'), occurence:1 (3.23%)\nsemantic type: ('noun.substance', 'adv.all'), occurence:1 (3.23%)\nsemantic type: ('adj.all', 'adv.all'), occurence:1 (3.23%)\nsemantic type: ('noun.food', 'noun.body'), occurence:1 (3.23%)\nsemantic type: ('noun.substance', 'verb.consumption'), occurence:1 (3.23%)\n******************************************************************\n\n\n"
     ]
    }
   ],
   "source": [
    "semantic_types = hanks.semantic_clustering(filler_senses)\n",
    "show_results(INPUT_VERB, fillers, filler_senses, semantic_types)"
   ]
  },
  {
   "source": [
    "### Risultati\n",
    "Come si può notare dall'output, le prestazione sono abbastanza deludenti. Emergono due dinamiche:\n",
    "\n",
    "* Spesso i filler corrispondenti all'argomento subject del verbo corrispondono a pronomi (I, she, they, ecc...) i quali non trovano una corrispondente lexical category in wordnet dunque lesk ritorna NONE , generando un semantic_type non-valido.\n",
    "\n",
    "* Come si può notare l'\"invalid semantic type\" (None, None) rappresenta il 68% delle occorrenze, indicativo di come sia lo step di WSD che il coverage del sense repository (WN) ricoprando un ruolo fondamentale per il risultato finale.\n",
    "\n",
    "Un importante osservazione da fare, che però non sorprende alla luce di quanto visto nel corso, è che lo step fondamentale che  ha l'impatto principale sull'intera pipeline è quello di **semantic-clustering**.\n",
    "\n",
    "Per limitare il problema dell'invalid semantictype `(None, None)`, è possibile settare l'argomento `apply_custom_rule=True` nella funzione `hanks.find_filler_senses`. Questo argomento permette di applicare delle regole per \"forzare\" l'individuazione del senso associato a particolari fillers (ad es. per i pronomi \"I\", \"you\", ... vedasi la funzione `hanks.pronoun_WSD_rule`)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Applying Hanks Theory for verb: eat\n\nCollocations Extracted:\n\nfiller: what - people\nsenses: None - Synset('citizenry.n.01')\n-------------------------------------------------------------\nfiller: Americans - fat\nsenses: Synset('american_english.n.01') - Synset('fatty.a.01')\n-------------------------------------------------------------\nfiller: one - skin\nsenses: Synset('one.s.03') - Synset('skin.v.02')\n-------------------------------------------------------------\nfiller: what - they\nsenses: None - None\n-------------------------------------------------------------\nfiller: students - cereal\nsenses: Synset('scholar.n.01') - Synset('grain.n.02')\n-------------------------------------------------------------\nfiller: they - it\nsenses: Synset('people.n.01') - Synset('information_technology.n.01')\n-------------------------------------------------------------\nfiller: students - cereal\nsenses: Synset('scholar.n.01') - Synset('grain.n.02')\n-------------------------------------------------------------\nfiller: they - it\nsenses: Synset('people.n.01') - Synset('information_technology.n.01')\n-------------------------------------------------------------\nfiller: I - rider\nsenses: Synset('one.n.01') - Synset('rider.n.01')\n-------------------------------------------------------------\nfiller: I - eggs\nsenses: Synset('iodine.n.01') - Synset('testis.n.01')\n-------------------------------------------------------------\nfiller: we - seed\nsenses: Synset('people.n.01') - Synset('seeded_player.n.01')\n-------------------------------------------------------------\nfiller: which - profits\nsenses: None - Synset('net_income.n.01')\n-------------------------------------------------------------\nfiller: who - celery\nsenses: Synset('world_health_organization.n.01') - Synset('celery.n.01')\n-------------------------------------------------------------\nfiller: I - soup\nsenses: Synset('one.s.01') - Synset('soup.n.02')\n-------------------------------------------------------------\nfiller: They - food\nsenses: None - Synset('food.n.02')\n-------------------------------------------------------------\nfiller: He - nothing\nsenses: Synset('helium.n.01') - Synset('nothing.r.01')\n-------------------------------------------------------------\nfiller: I - more\nsenses: Synset('one.s.01') - Synset('more.r.02')\n-------------------------------------------------------------\nfiller: Charlie - supper\nsenses: None - Synset('supper.n.01')\n-------------------------------------------------------------\nfiller: she - dinner\nsenses: Synset('person.n.01') - Synset('dinner.n.01')\n-------------------------------------------------------------\nfiller: you - it\nsenses: Synset('person.n.01') - Synset('information_technology.n.01')\n-------------------------------------------------------------\nfiller: fish - bodies\nsenses: Synset('fish.n.02') - Synset('torso.n.01')\n-------------------------------------------------------------\nfiller: what - I\nsenses: None - Synset('one.s.01')\n-------------------------------------------------------------\nfiller: you - dust\nsenses: Synset('person.n.01') - Synset('dust.v.02')\n-------------------------------------------------------------\nfiller: He - litle\nsenses: Synset('helium.n.01') - None\n-------------------------------------------------------------\nfiller: He - litle\nsenses: Synset('helium.n.01') - None\n-------------------------------------------------------------\nfiller: He - breakfast\nsenses: Synset('helium.n.01') - Synset('breakfast.v.02')\n-------------------------------------------------------------\nfiller: they - other\nsenses: Synset('people.n.01') - Synset('other.s.04')\n-------------------------------------------------------------\nfiller: They - breakfast\nsenses: None - Synset('breakfast.v.02')\n-------------------------------------------------------------\nfiller: She - bread\nsenses: None - Synset('bread.v.01')\n-------------------------------------------------------------\nfiller: They - chickens\nsenses: None - Synset('chicken.n.02')\n-------------------------------------------------------------\nfiller: they - chickens\nsenses: Synset('people.n.01') - Synset('wimp.n.01')\n-------------------------------------------------------------\n\nSemantic Types Clusters for eat:\n\nsemantic type: (None, None), occurence:11 (35.48%)\nsemantic type: ('noun.person', 'noun.food'), occurence:2 (6.45%)\nsemantic type: ('noun.group', 'noun.cognition'), occurence:2 (6.45%)\nsemantic type: ('noun.group', 'noun.person'), occurence:2 (6.45%)\nsemantic type: ('noun.communication', 'adj.all'), occurence:1 (3.23%)\nsemantic type: ('adj.all', 'verb.contact'), occurence:1 (3.23%)\nsemantic type: ('noun.quantity', 'noun.person'), occurence:1 (3.23%)\nsemantic type: ('noun.substance', 'noun.body'), occurence:1 (3.23%)\nsemantic type: ('noun.group', 'noun.plant'), occurence:1 (3.23%)\nsemantic type: ('adj.all', 'noun.substance'), occurence:1 (3.23%)\nsemantic type: ('noun.substance', 'adv.all'), occurence:1 (3.23%)\nsemantic type: ('adj.all', 'adv.all'), occurence:1 (3.23%)\nsemantic type: ('noun.Tops', 'noun.food'), occurence:1 (3.23%)\nsemantic type: ('noun.Tops', 'noun.cognition'), occurence:1 (3.23%)\nsemantic type: ('noun.food', 'noun.body'), occurence:1 (3.23%)\nsemantic type: ('noun.Tops', 'verb.contact'), occurence:1 (3.23%)\nsemantic type: ('noun.substance', 'verb.consumption'), occurence:1 (3.23%)\nsemantic type: ('noun.group', 'adj.all'), occurence:1 (3.23%)\n******************************************************************\n\n\n"
     ]
    }
   ],
   "source": [
    "filler_senses = hanks.find_filler_senses(fillers, wsd.lesk, apply_custom_rule=True)\n",
    "semantic_types = hanks.semantic_clustering(filler_senses)\n",
    "show_results(INPUT_VERB, fillers, filler_senses, semantic_types)"
   ]
  },
  {
   "source": [
    "Confrontando questo output con quello precedente possiamo osservare che la frequenza dell' invalid semantic type si è (approssimativamente) dimezzata dall' $61\\%$ al $35\\%$ per effetto della regola applicata. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Batch Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " occurence:1 (0.96%)\n",
      "semantic type: ('noun.group', 'noun.quantity'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.artifact', 'noun.state'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.attribute', 'verb.communication'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.group', 'noun.cognition'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.substance', 'noun.act'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.group', 'noun.Tops'), occurence:1 (0.96%)\n",
      "semantic type: ('verb.contact', 'noun.Tops'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.attribute', 'noun.Tops'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.object', 'verb.stative'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.person', 'noun.feeling'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.Tops', 'noun.group'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.cognition', 'noun.cognition'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.group', 'noun.possession'), occurence:1 (0.96%)\n",
      "semantic type: ('adj.all', 'noun.location'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.feeling', 'noun.person'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.substance', 'noun.substance'), occurence:1 (0.96%)\n",
      "semantic type: ('adj.all', 'noun.feeling'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.group', 'noun.person'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.communication', 'adv.all'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.cognition', 'noun.state'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.location', 'noun.Tops'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.body', 'noun.possession'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.shape', 'noun.cognition'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.quantity', 'noun.attribute'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.artifact', 'noun.group'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.time', 'noun.group'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.artifact', 'noun.shape'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.substance', 'verb.stative'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.act', 'noun.cognition'), occurence:1 (0.96%)\n",
      "semantic type: ('adj.all', 'verb.cognition'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.group', 'verb.stative'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.substance', 'noun.location'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.substance', 'noun.group'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.animal', 'noun.animal'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.body', 'noun.location'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.group', 'noun.group'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.substance', 'noun.possession'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.artifact', 'noun.possession'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.cognition', 'noun.person'), occurence:1 (0.96%)\n",
      "semantic type: ('adj.all', 'noun.Tops'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.substance', 'noun.body'), occurence:1 (0.96%)\n",
      "semantic type: ('noun.group', 'verb.creation'), occurence:1 (0.96%)\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "Applying Hanks Theory for verb: run\n",
      "\n",
      "Collocations Extracted:\n",
      "\n",
      "filler: benefits - billion\n",
      "senses: Synset('benefit.n.03') - Synset('billion.s.01')\n",
      "-------------------------------------------------------------\n",
      "filler: He - string\n",
      "senses: Synset('helium.n.01') - Synset('string.n.04')\n",
      "-------------------------------------------------------------\n",
      "filler: who - shop\n",
      "senses: Synset('world_health_organization.n.01') - Synset('shop.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: Maris - dash\n",
      "senses: Synset('cheremis.n.01') - Synset('hyphen.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: who - organization\n",
      "senses: Synset('world_health_organization.n.01') - Synset('administration.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: Casualties - men\n",
      "senses: Synset('casualty.n.04') - Synset('valet.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: Styles - gamut\n",
      "senses: Synset('style.n.05') - Synset('gamut.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: networks - tapes\n",
      "senses: Synset('net.n.06') - Synset('wiretap.v.01')\n",
      "-------------------------------------------------------------\n",
      "filler: stations - transcripts\n",
      "senses: Synset('stations.n.01') - Synset('transcript.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: action - risk\n",
      "senses: Synset('natural_process.n.01') - Synset('gamble.v.01')\n",
      "-------------------------------------------------------------\n",
      "filler: attempt - risk\n",
      "senses: Synset('try.v.01') - Synset('risk.n.03')\n",
      "-------------------------------------------------------------\n",
      "filler: we - world\n",
      "senses: Synset('people.n.01') - Synset('worldly_concern.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: who - gamut\n",
      "senses: Synset('world_health_organization.n.01') - Synset('gamut.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: rates - same\n",
      "senses: Synset('rates.n.01') - Synset('lapp.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: we - survey\n",
      "senses: Synset('people.n.01') - Synset('survey.v.05')\n",
      "-------------------------------------------------------------\n",
      "filler: concessionaire - cafeteria\n",
      "senses: Synset('concessionaire.n.01') - Synset('cafeteria.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: ditcher - trenches\n",
      "senses: None - Synset('trench.v.06')\n",
      "-------------------------------------------------------------\n",
      "filler: Discounts - %\n",
      "senses: Synset('rebate.n.01') - None\n",
      "-------------------------------------------------------------\n",
      "filler: we - string\n",
      "senses: Synset('people.n.01') - Synset('string.n.04')\n",
      "-------------------------------------------------------------\n",
      "filler: brother - mile\n",
      "senses: Synset('brother.n.05') - Synset('nautical_mile.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: club - trips\n",
      "senses: Synset('club.n.06') - Synset('trip.v.04')\n",
      "-------------------------------------------------------------\n",
      "filler: she - distance\n",
      "senses: Synset('person.n.01') - Synset('distance.n.05')\n",
      "-------------------------------------------------------------\n",
      "filler: he - race\n",
      "senses: Synset('helium.n.01') - Synset('race.v.02')\n",
      "-------------------------------------------------------------\n",
      "filler: they - risk\n",
      "senses: Synset('people.n.01') - Synset('gamble.v.01')\n",
      "-------------------------------------------------------------\n",
      "filler: Republicans - Senate\n",
      "senses: Synset('republican.n.03') - Synset('united_states_senate.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: message - risk\n",
      "senses: Synset('message.v.01') - Synset('risk.v.01')\n",
      "-------------------------------------------------------------\n",
      "filler: he - show\n",
      "senses: Synset('helium.n.01') - Synset('show.v.10')\n",
      "-------------------------------------------------------------\n",
      "filler: he - American\n",
      "senses: Synset('helium.n.01') - Synset('american.n.03')\n",
      "-------------------------------------------------------------\n",
      "filler: he - American\n",
      "senses: Synset('helium.n.01') - Synset('american.n.03')\n",
      "-------------------------------------------------------------\n",
      "filler: who - colony\n",
      "senses: Synset('world_health_organization.n.01') - Synset('colony.n.04')\n",
      "-------------------------------------------------------------\n",
      "filler: who - bureau\n",
      "senses: Synset('world_health_organization.n.01') - Synset('chest_of_drawers.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: who - agencies\n",
      "senses: Synset('world_health_organization.n.01') - Synset('representation.n.04')\n",
      "-------------------------------------------------------------\n",
      "filler: Who - store\n",
      "senses: Synset('world_health_organization.n.01') - Synset('shop.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: who - it\n",
      "senses: Synset('world_health_organization.n.01') - Synset('information_technology.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: concern - businesses\n",
      "senses: Synset('business.n.01') - Synset('business.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: achievement - second\n",
      "senses: Synset('accomplishment.n.01') - Synset('second_gear.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: filling - looms\n",
      "senses: Synset('filling.n.06') - Synset('loom.v.04')\n",
      "-------------------------------------------------------------\n",
      "filler: reduction - part\n",
      "senses: Synset('reduction.n.02') - Synset('part.n.09')\n",
      "-------------------------------------------------------------\n",
      "filler: upswing - course\n",
      "senses: None - Synset('course.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: pricks - it\n",
      "senses: Synset('prickle.v.03') - Synset('information_technology.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: Committeemen - some\n",
      "senses: Synset('committeeman.n.01') - Synset('some.a.01')\n",
      "-------------------------------------------------------------\n",
      "filler: dog - ing\n",
      "senses: Synset('pawl.n.01') - None\n",
      "-------------------------------------------------------------\n",
      "filler: Bathyrans - check\n",
      "senses: None - Synset('check.v.18')\n",
      "-------------------------------------------------------------\n",
      "filler: Watson - ladder\n",
      "senses: Synset('watson.n.03') - Synset('ladder.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: two - sails\n",
      "senses: Synset('deuce.n.04') - Synset('sail.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: He - finger\n",
      "senses: Synset('helium.n.01') - Synset('finger.n.03')\n",
      "-------------------------------------------------------------\n",
      "filler: We - note\n",
      "senses: None - Synset('note.v.04')\n",
      "-------------------------------------------------------------\n",
      "filler: she - them\n",
      "senses: Synset('person.n.01') - Synset('person.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: she - them\n",
      "senses: Synset('person.n.01') - Synset('person.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: buildings - length\n",
      "senses: Synset('building.n.04') - Synset('length.n.05')\n",
      "-------------------------------------------------------------\n",
      "filler: He - eye\n",
      "senses: Synset('helium.n.01') - Synset('eye.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: he - boat\n",
      "senses: Synset('helium.n.01') - Synset('boat.v.01')\n",
      "-------------------------------------------------------------\n",
      "filler: thought - circles\n",
      "senses: Synset('thought.n.03') - Synset('traffic_circle.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: ship - rogue\n",
      "senses: Synset('ship.v.05') - Synset('rogue.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: ship - rogue\n",
      "senses: Synset('ship.v.05') - Synset('rogue.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: that - way\n",
      "senses: None - Synset('way.n.11')\n",
      "-------------------------------------------------------------\n",
      "filler: Mike - line\n",
      "senses: Synset('microphone.n.01') - Synset('wrinkle.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: father - him\n",
      "senses: Synset('founder.n.02') - None\n",
      "-------------------------------------------------------------\n",
      "filler: He - rooms\n",
      "senses: Synset('helium.n.01') - Synset('suite.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: Russ - steps\n",
      "senses: Synset('rus.n.01') - Synset('step.n.10')\n",
      "-------------------------------------------------------------\n",
      "filler: who - one\n",
      "senses: Synset('world_health_organization.n.01') - Synset('one.s.02')\n",
      "-------------------------------------------------------------\n",
      "filler: We - house\n",
      "senses: None - Synset('house.n.09')\n",
      "-------------------------------------------------------------\n",
      "filler: you - nursery\n",
      "senses: Synset('person.n.01') - Synset('greenhouse.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: magazine - photograph\n",
      "senses: Synset('magazine.n.05') - Synset('photograph.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: circle - Emma\n",
      "senses: Synset('circle.n.03') - None\n",
      "-------------------------------------------------------------\n",
      "filler: you - bases\n",
      "senses: Synset('person.n.01') - Synset('base.n.14')\n",
      "-------------------------------------------------------------\n",
      "filler: You - war\n",
      "senses: None - Synset('war.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: he - flag\n",
      "senses: Synset('helium.n.01') - Synset('pin.n.08')\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Semantic Types Clusters for run:\n",
      "\n",
      "semantic type: (None, None), occurence:11 (16.18%)\n",
      "semantic type: ('noun.group', 'noun.artifact'), occurence:4 (5.88%)\n",
      "semantic type: ('noun.group', 'noun.group'), occurence:3 (4.41%)\n",
      "semantic type: ('noun.substance', 'noun.artifact'), occurence:3 (4.41%)\n",
      "semantic type: ('noun.group', 'noun.cognition'), occurence:2 (2.94%)\n",
      "semantic type: ('noun.person', 'noun.artifact'), occurence:2 (2.94%)\n",
      "semantic type: ('noun.substance', 'noun.person'), occurence:2 (2.94%)\n",
      "semantic type: ('noun.artifact', 'noun.artifact'), occurence:2 (2.94%)\n",
      "semantic type: ('noun.Tops', 'noun.Tops'), occurence:2 (2.94%)\n",
      "semantic type: ('verb.contact', 'noun.person'), occurence:2 (2.94%)\n",
      "semantic type: ('noun.communication', 'adj.all'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.substance', 'noun.group'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.person', 'noun.communication'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.event', 'noun.person'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.plant', 'noun.communication'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.artifact', 'verb.perception'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.act', 'noun.communication'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.process', 'verb.social'), occurence:1 (1.47%)\n",
      "semantic type: ('verb.social', 'noun.attribute'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.group', 'noun.communication'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.possession', 'noun.communication'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.group', 'verb.cognition'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.person', 'noun.quantity'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.artifact', 'verb.creation'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.Tops', 'noun.time'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.substance', 'verb.competition'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.group', 'verb.social'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.object', 'noun.group'), occurence:1 (1.47%)\n",
      "semantic type: ('verb.communication', 'verb.social'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.substance', 'verb.communication'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.group', 'noun.location'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.group', 'noun.state'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.act', 'noun.artifact'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.act', 'verb.creation'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.process', 'noun.cognition'), occurence:1 (1.47%)\n",
      "semantic type: ('verb.contact', 'noun.cognition'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.person', 'adj.all'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.substance', 'noun.body'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.substance', 'verb.motion'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.cognition', 'noun.artifact'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.artifact', 'noun.shape'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.location', 'noun.artifact'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.group', 'adj.all'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.Tops', 'noun.artifact'), occurence:1 (1.47%)\n",
      "semantic type: ('noun.Tops', 'noun.location'), occurence:1 (1.47%)\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "Applying Hanks Theory for verb: fight\n",
      "\n",
      "Collocations Extracted:\n",
      "\n",
      "filler: Vietnamese - troops\n",
      "senses: Synset('vietnamese.a.01') - Synset('troop.v.02')\n",
      "-------------------------------------------------------------\n",
      "filler: bloc - committee\n",
      "senses: Synset('bloc.n.01') - Synset('committee.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: Union - conventional\n",
      "senses: Synset('union.s.01') - Synset('conventional.s.06')\n",
      "-------------------------------------------------------------\n",
      "filler: Jones - Commies\n",
      "senses: Synset('jones.n.02') - Synset('communist.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: he - Batista\n",
      "senses: Synset('helium.n.01') - Synset('person.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: he - charm\n",
      "senses: Synset('helium.n.01') - Synset('charm.v.04')\n",
      "-------------------------------------------------------------\n",
      "filler: he - temptation\n",
      "senses: Synset('helium.n.01') - Synset('temptation.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: forces - action\n",
      "senses: Synset('force_out.n.01') - Synset('natural_process.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: they - way\n",
      "senses: Synset('people.n.01') - Synset('way.n.11')\n",
      "-------------------------------------------------------------\n",
      "filler: classes - interdependence\n",
      "senses: Synset('course.n.01') - Synset('mutuality.n.02')\n",
      "-------------------------------------------------------------\n",
      "filler: Acheson - battle\n",
      "senses: Synset('acheson.n.01') - Synset('battle.v.01')\n",
      "-------------------------------------------------------------\n",
      "filler: he - battles\n",
      "senses: Synset('helium.n.01') - Synset('battle.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: who - trusts\n",
      "senses: Synset('world_health_organization.n.01') - Synset('trust.n.04')\n",
      "-------------------------------------------------------------\n",
      "filler: He - it\n",
      "senses: Synset('helium.n.01') - Synset('information_technology.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: I - so\n",
      "senses: Synset('one.s.01') - Synset('therefore.r.01')\n",
      "-------------------------------------------------------------\n",
      "filler: Jeep - way\n",
      "senses: Synset('jeep.n.01') - Synset('way.n.11')\n",
      "-------------------------------------------------------------\n",
      "filler: Poet - Nick\n",
      "senses: Synset('poet.n.01') - Synset('notch.n.04')\n",
      "-------------------------------------------------------------\n",
      "filler: he - wheel\n",
      "senses: Synset('helium.n.01') - Synset('roulette_wheel.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: He - impulse\n",
      "senses: Synset('helium.n.01') - Synset('pulsation.n.01')\n",
      "-------------------------------------------------------------\n",
      "filler: He - panic\n",
      "senses: Synset('helium.n.01') - Synset('panic.v.02')\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Semantic Types Clusters for fight:\n",
      "\n",
      "semantic type: ('noun.group', 'noun.group'), occurence:2 (10.00%)\n",
      "semantic type: ('adj.pert', 'verb.motion'), occurence:1 (5.00%)\n",
      "semantic type: ('adj.all', 'adj.all'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.person', 'noun.person'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.substance', 'noun.Tops'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.substance', 'verb.communication'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.substance', 'noun.feeling'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.act', 'noun.process'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.group', 'noun.cognition'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.act', 'noun.relation'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.person', 'verb.competition'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.substance', 'noun.act'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.substance', 'noun.cognition'), occurence:1 (5.00%)\n",
      "semantic type: ('adj.all', 'adv.all'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.artifact', 'noun.cognition'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.person', 'noun.act'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.substance', 'noun.artifact'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.substance', 'noun.event'), occurence:1 (5.00%)\n",
      "semantic type: ('noun.substance', 'verb.emotion'), occurence:1 (5.00%)\n",
      "******************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.wsd import lesk\n",
    "\n",
    "target_verbs = ['eat', 'meet', 'run', 'fight']\n",
    "valence = 2\n",
    "\n",
    "for target_verb in target_verbs:\n",
    "    fillers, filler_senses, semantic_types = hanks.compute_hanks(target_verb, valence=2, corpus=brown, wsd_func=lesk, apply_rule = True)\n",
    "    show_results(target_verb, fillers, filler_senses, semantic_types)"
   ]
  }
 ]
}